- ğŸ‘‹ Hi, Iâ€™m @Rachetangle
- ğŸ‘€ Iâ€™m interested in ...
- ğŸŒ± Iâ€™m currently learning ...
- ğŸ’ï¸ Iâ€™m looking to collaborate on ...
- ğŸ“« How to reach me ...
- ğŸ˜„ Pronouns: ...
- âš¡ Fun fact: ...

<!---
Rachetangle/Rachetangle is a âœ¨ special âœ¨ repository because its `README.md` (this file) appears on your GitHub profile.
You can click the Preview link to take a look at your changes.
--->
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Texto a MÃºsica</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      text-align: center;
      margin: 50px;
    }
    button {
      padding: 10px 20px;
      font-size: 16px;
      margin: 20px;
    }
    .output {
      margin-top: 20px;
      font-size: 18px;
    }
  </style>
</head>
<body>
  <h1>De Voz a MÃºsica</h1>
  <p>Presiona el botÃ³n y habla para convertir tu voz en texto y mÃºsica.</p>
  <button id="record-btn">ğŸ¤ Grabar Voz</button>
  <div class="output">
    <p><strong>Texto Detectado:</strong> <span id="detected-text">[Nada aÃºn]</span></p>
    <p><strong>Generando MÃºsica...</strong></p>
    <audio id="audio-player" controls></audio>
  </div>

  <script>
    // Verificar si el navegador soporta reconocimiento de voz
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    if (!SpeechRecognition) {
      alert("Tu navegador no soporta reconocimiento de voz.");
    } else {
      const recognition = new SpeechRecognition();
      recognition.lang = "es-ES"; // Idioma espaÃ±ol
      const recordBtn = document.getElementById("record-btn");
      const detectedText = document.getElementById("detected-text");
      const audioPlayer = document.getElementById("audio-player");

      // Capturar voz al hacer clic en el botÃ³n
      recordBtn.addEventListener("click", () => {
        detectedText.textContent = "Escuchando...";
        recognition.start();
      });

      // Procesar texto detectado
      recognition.onresult = (event) => {
        const text = event.results[0][0].transcript;
        detectedText.textContent = text;

        // Generar mÃºsica simulada
        generateMusic(text);
      };

      recognition.onerror = (event) => {
        detectedText.textContent = "Error: " + event.error;
      };
    }

    // Generar mÃºsica bÃ¡sica basada en texto
    function generateMusic(text) {
      const context = new (window.AudioContext || window.webkitAudioContext)();
      const oscillator = context.createOscillator();
      const gainNode = context.createGain();

      // Conectar nodos
      oscillator.connect(gainNode);
      gainNode.connect(context.destination);

      // Ajustar frecuencia en funciÃ³n del texto
      let freq = 440; // Frecuencia base
      if (text.length > 0) {
        freq += text.length * 10; // Incremento segÃºn longitud del texto
      }
      oscillator.frequency.setValueAtTime(freq, context.currentTime);

      // Configurar tipo de onda
      oscillator.type = "sine";

      // Reproducir tono
      oscillator.start();
      setTimeout(() => oscillator.stop(), 1000); // DuraciÃ³n de 1 segundo

      // Simular audio generado
      audioPlayer.src = "data:audio/wav;base64,UklGRigAAABXQVZFZm10IBAAAAABAAEAgD4AAAB9AAACABAAZGF0YYoAAACAgICAgICAgICAgICAgICAgICAgICAg"; // Placeholder
    }
  </script>
</body>
</html>
